- acceptance_criteria:
  - something done
  id: CODEX-EXAMPLE-01
  priority: low
  steps:
  - do something
  title: Example task
- acceptance_criteria:
  - Given a recalled plan template exists
  - When a similar query is submitted
  - Then the resulting plan has fewer nodes than the baseline
  id: P3-TEST-01
  notes: '`services/tool_registry/__init__.py` uses `datetime.utcnow()` which is deprecated
    in Python 3.12. Replace with `datetime.now(datetime.UTC)` to ensure timezone-aware
    timestamps.'
  priority: medium
  status: open
  steps:
  - Investigate Supervisor merging logic
  - Add regression test for plan length reduction
  title: Replace deprecated utcnow usage
- acceptance_criteria:
  - MemoryManager stores skills with policy, embedding and metadata
  - SkillLibrary exposes vector and metadata query endpoints
  id: CR-001
  priority: medium
  steps:
  - Design SkillLibrary schema with policy, representation and metadata fields
  - Refactor MemoryManager to use the SkillLibrary for storage and retrieval
  - Implement semantic lookup APIs by embedding or metadata filters
  - Ensure compatibility with episodic and semantic memory modules
  - Add unit tests and update documentation
  title: SkillLibrary-based MemoryManager overhaul
- acceptance_criteria:
  - URL discovers disentangled skills for the SkillLibrary
  id: CR-002
  priority: medium
  steps:
  - Research and select a URL framework focusing on the DUSDi algorithm
  - Integrate environment interface for reward-free exploration
  - Implement mutual-information objective for disentangled skill learning
  - Store discovered skills and metadata in the SkillLibrary
  - Evaluate diversity and disentanglement metrics
  title: Unsupervised SkillDiscoveryModule
- acceptance_criteria:
  - LLM-generated sub-tasks and rewards stored in skill metadata
  id: CR-003
  priority: medium
  steps:
  - Define interface and prompt templates for the LLM to describe sub-tasks
  - Translate LLM output into reward functions and termination conditions
  - Integrate L2S/LDSC framework to generate structured skill specs
  - Persist semantic scaffolding in skill metadata
  - Test with sample tasks and refine prompts
  title: LLM-guided semantic skill decomposition
- acceptance_criteria:
  - Manager selects goals and Worker executes skills via HRL
  id: CR-004
  priority: medium
  steps:
  - Design two-level FuN architecture with Manager and Worker policies
  - Implement goal-conditioned Worker using intrinsic rewards
  - Sequence skills using SkillLibrary embeddings for goal selection
  - Validate integration with MemoryManager and other modules
  - Add integration tests for long-horizon tasks
  title: Hierarchical Policy Executor
- acceptance_criteria:
  - New skills added without overwriting existing ones
  id: CR-005
  priority: medium
  steps:
  - Diversify training environments to learn invariant features
  - Freeze existing skills and modularize SkillLibrary for expansion
  - Compose new skills via Primitive Prompt Learning
  - Continuously evaluate transfer and generalization
  title: Lifelong skill generalization support
- acceptance_criteria:
  - RL training uses Ray RLlib and NVIDIA Isaac Lab
  id: CR-006
  priority: medium
  steps: []
  title: Adopt RLlib and Isaac Lab tooling
- acceptance_criteria:
  - docs/change-requests.md aggregates suggestions by topic
  - codex_tasks.md references this issue
  id: CODEX-CR-COLLECT-02
  issue: TBD
  priority: low
  steps: []
  title: Consolidate scattered change-request suggestions
- acceptance_criteria:
  - Overlapping entries are consolidated in codex_tasks.md
  - docs/change-requests.md notes consolidation date
  - Issue link is recorded here
  id: CODEX-CR-RATIONALISE-03
  issue: TBD
  priority: low
  steps: []
  title: Rationalise overlap between change_requests.md and codex_tasks.md
- acceptance_criteria:
  - Gap analysis report produced
  - Task flow diagram with pain points
  - AGENTS.md and codex_tasks updated with examples and new metadata support
  id: CR-AI-16
  priority: medium
  steps:
  - Audit AGENTS.md against runtime behaviors
  - Trace task lifecycle from queue to completion
  - Propose doc updates and logic refinements
  title: Analyse & Enhance Codex Agent Experience
- acceptance_criteria:
  - Given an agent issues any tool call
  - When the call completes or is blocked
  - Then a log entry is emitted with timestamp, agent_id, action, intent, and outcome
  id: CR-05c
  priority: medium
  steps: []
  title: Enable Continuous Monitoring & Auditing
- acceptance_criteria:
  - All @pytest.mark.core tests (including sandbox) pass under the parallel runner.
  - optional and integration tests continue to pass in their respective CI jobs.
  id: CR-05b-04
  priority: low
  steps:
  - Rerun `test_sandbox.py` under the new core suite to confirm sandbox isolation
    and timeouts still work.
  - Execute the 'optional' and 'integration' markers locally and in CI to catch any
    regressions in slow or optional tests.
  - Fix any failures (e.g. missing fixtures, new dependency issues, or timeouts).
  title: Verify sandbox and optional-suite stability post-migration
- acceptance_criteria:
  - Planner queries the reputation API before assigning tasks
  - Weighted sum considers reputation score, token cost and load
  id: CR-04
  priority: medium
  steps:
  - integrate Planner with Reputation Service via GET /v1/reputation/query
  - compute weighted utility using reputation, cost, and current load
  - allocate tasks to maximize utility
  title: Agent Modification - Planner Agent Enhancement
- acceptance_criteria:
  - Edges and nodes styled based on agent-provided confidence scores
  - Agent's primary intended plan visually distinct
  - Selecting a belief node reveals the evidence chain
  id: CR-1.2
  priority: medium
  steps: []
  title: Uncertainty & Intent Display
- acceptance_criteria:
  - A "What-If" mode can be toggled on, creating a non-destructive simulation environment.
  - Within this mode, operators can modify plan parameters and trigger a re-simulation.
  - The UI displays the original and simulated plans side-by-side with updated KPIs.
  - Simulation logs are kept separate from the primary execution logs.
  id: CR-1.3
  priority: medium
  steps: []
  title: What-If Simulation Mode
- acceptance_criteria:
  - All services run under FastAPI with no blocking calls
  - Existing endpoints behave identically
  id: CR-P4-01A
  priority: high
  steps:
  - Replace HTTPServer usage in ToolRegistryServer and LTMServiceServer with FastAPI
    apps
  - Update docker-compose and helm charts to launch uvicorn workers
  title: Complete FastAPI migration for all services
- acceptance_criteria:
  - CI test passes showing cache hit/miss counts
  id: CR-P4-02A
  priority: medium
  steps:
  - Generate enough unique texts to exceed EMBED_CACHE_SIZE
  - Assert cache size is capped and LRU eviction occurs
  title: Add CI smoke test for embedding cache eviction
- acceptance_criteria:
  - monitoring service emits cpu_usage and memory_usage metrics
  id: CR-P4-03A
  priority: high
  steps:
  - Integrate psutil to record process CPU and RSS values
  - Export metrics through OpenTelemetry
  title: Expose CPU and memory metrics via SystemMonitor
- acceptance_criteria:
  - Invalid inputs are logged with timestamp and caller information
  id: CR-P4-04A
  priority: medium
  steps:
  - Update validate_path_or_url to log InputValidationError details
  - Add unit test verifying log output
  title: Log invalid path and URL validation attempts
- acceptance_criteria:
  - Tasks are routed to specialized agents when available
  id: CR-P4-05A
  priority: high
  steps:
  - Store agent skill metadata in ProceduralMemoryService
  - Modify Supervisor to choose the best-matching specialist
  title: Implement specialist agent selection logic
- acceptance_criteria:
  - New tests fail on regression and pass on baseline implementation
  id: CR-P4-06A
  priority: medium
  steps:
  - Add integration tests covering FM-1.3, FM-2.4, and FM-3.3 scenarios
  title: Implement MAST tests for Step Repetition, Information Withholding, and Incorrect
    Verification
- acceptance_criteria:
  - Agents can run parameterized SQL queries through the registry
  id: CR-P4-07A
  priority: medium
  steps:
  - Implement connectors for SQLite and PostgreSQL
  - Register tools with appropriate RBAC rules
  title: Add SQL query tool connectors to Tool Registry
- acceptance_criteria:
  - New document linked from mkdocs navigation
  id: CR-P4-08A
  priority: low
  steps:
  - Summarize proposed data model and API
  - Add research report under docs/research/
  title: Document spatio-temporal memory research findings
- acceptance_criteria:
  - Onboarding guide includes caching configuration section
  id: CR-P4-09A
  priority: low
  steps:
  - Explain EMBED_CACHE_SIZE and caching benefits
  - Reference scripts/agent-setup.sh for environment setup
  title: Update onboarding docs with embedding cache guidance
- acceptance_criteria:
  - Specialist agent receives a tagged task when its specialization score is highest
  - Generalist agent used when no specialist exceeds threshold
  id: CR-P4-07R
  priority: high
  steps:
  - Extend Supervisor to query ProceduralMemoryService for agent skill metadata
  - Compute specialization score and route tasks accordingly
  - Log routing decisions and scores
  title: Implement Specialist Agent Selection
- acceptance_criteria:
  - Evaluator persists structured critique records after each run
  - Retrieval API returns relevant risk cases for new prompts
  id: CR-2.1
  priority: high
  steps:
  - Add dedicated storage for Evaluator risk cases
  - Serialize past critiques with metadata for retrieval
  - Expose memory operations via LTM service
  title: Implement AgentAuditor experiential memory
- acceptance_criteria:
  - Given a prompt similar to a stored risk case
  - When the Evaluator runs
  - Then its critique references the prior case
  id: CR-2.2
  priority: high
  steps:
  - Retrieve top past cases from experiential memory
  - Inject retrieved examples into Evaluator reasoning chain
  - Tune prompt to use Chain-of-Thought with references
  title: Integrate RAG-based recall in Evaluator
- acceptance_criteria:
  - Unauthorized requests to Evaluator endpoints return 401
  - Authorized calls succeed with token-based authentication
  id: CR-2.3
  priority: high
  steps:
  - Require OAuth token on all Evaluator service endpoints
  - Validate tokens before processing any request
  - Update client agents to include authentication headers
  title: Secure Evaluator API authentication
- acceptance_criteria:
  - Security Agent returns a numeric credibility score for any agent id
  - Scores update based on recent behavior metrics
  id: CR-3.1
  priority: high
  steps:
  - Implement service calculating real-time reputation vectors
  - Maintain credibility score per agent in shared store
  - Expose score query API to orchestration engine
  title: Deploy Security Agent with credibility scoring
- acceptance_criteria:
  - Low-credibility agents have reduced influence on final output
  - Aggregation tests demonstrate score-weighted decisions
  id: CR-3.2
  priority: high
  steps:
  - Modify output aggregator to weight contributions by credibility score
  - Update documentation and tests for new weighting logic
  title: Integrate credibility-aware aggregation
- acceptance_criteria:
  - Sudden spikes in traffic trigger anomaly alerts
  - Logged alerts include offending agent ids and timestamps
  id: CR-3.3
  priority: high
  steps:
  - Stream group chat traffic to Security Agent
  - Detect deviations in message frequency or size
  - Raise alerts for suspected covert channels
  title: Monitor inter-agent communication for anomalies
- acceptance_criteria:
  - Ingestion from untrusted sources is rejected with an error
  - Audit log records decision with source reputation value
  id: CR-4.1
  priority: high
  steps:
  - Implement reputation checks for external data sources
  - Block ingestion when source score falls below threshold
  - Log verification outcomes for auditing
  title: Verify source credibility on LTM ingestion
- acceptance_criteria:
  - Retrieval filter removes AGENTPOISON-style backdoor prompts
  - Sanitized documents pass subsequent safety checks
  id: CR-4.2
  priority: high
  steps:
  - Sanitize documents after retrieval from LTM
  - Strip or quarantine suspicious payloads before agent use
  title: Add retrieval-time filtering for LTM
- acceptance_criteria:
  - Embedding monitor reports unusual data points
  - Alerts include reference to offending record ids
  id: CR-4.3
  priority: high
  steps:
  - Periodically scan embedding space for outlier clusters
  - Flag anomalies for manual review and potential purge
  title: Continuous anomaly detection on LTM embeddings
- acceptance_criteria:
  - High-risk operations route through Dual LLM sandbox
  - Documentation outlines quarantine vs privileged responsibilities
  id: CR-5.1
  priority: high
  steps:
  - Separate privileged and quarantined agents for risky tasks
  - Document pattern in architecture guides
  - Enforce separation in orchestration logic
  title: Formalize Dual LLM sandbox pattern
- acceptance_criteria:
  - Protocol compliance checks pass during integration tests
  - Violations trigger security alerts with message details
  id: CR-5.2
  priority: high
  steps:
  - Audit inter-agent messaging for adherence to defined schema
  - Block or log any attempt to use emergent private languages
  title: Enforce LLM-grounded communication protocols
- acceptance_criteria:
  - Provenance query returns full history for a memory id
  - CI tests verify metadata recorded on ingestion
  id: CR-5.3
  priority: high
  steps:
  - Track origin and transformations of data stored in LTM
  - Persist provenance metadata alongside memory records
  - Provide API to query provenance for any item
  title: Implement ML-BOM data provenance tracking
- acceptance_criteria:
  - Service blocks unsafe prompts and masks sensitive data
  - Audit logs capture original prompt and moderation result
  id: CR-EA-01
  priority: medium
  steps:
  - Define HTTP API for input/output validation
  - Implement prompt injection and PII detection
  - Record all moderation actions in an audit log
  title: Implement Guardrail Orchestration Service
- acceptance_criteria:
  - Safeguard agent logs blocked actions with reasons
  - High-risk events generate notifications for human oversight
  id: CR-EA-02
  priority: medium
  steps:
  - Monitor inter-agent messages and tool usage
  - Enforce policy manifest to block unsafe actions
  - Escalate high-risk events for human review
  title: Develop Parallel Safeguard Agent
- acceptance_criteria:
  - Repository contains constitution.yaml with approved principles
  - Council meeting notes archived for traceability
  id: CR-EA-03
  priority: medium
  steps:
  - Convene AI Safety Council to draft principles
  - Convert principles into machine-readable rules
  - Store constitution in version control
  title: Formalize System Constitution
- acceptance_criteria:
  - Training pipeline uses constitution for feedback generation
  - Reward model artifacts saved with version and config metadata
  id: CR-EA-04
  priority: medium
  steps:
  - Integrate constitution-based self-critique in supervised phase
  - Collect preference data via Safeguard agent scoring
  - Train preference model as reward function
  title: Re-architect RLAIF Loop for Constitutional Alignment
- acceptance_criteria:
  - Benchmark pipeline runs in CI with summary metrics
  - Alerts trigger when harmfulness exceeds threshold
  id: CR-EA-05
  priority: medium
  steps:
  - Generate adversarial prompts automatically
  - Score outputs with LLM-as-judge for harmfulness and neutrality
  - Track metrics over time and report regressions
  title: Establish Continuous Adversarial Benchmarking
- acceptance_criteria:
  - Assurance plan stored in docs/governance contains evidence map
  - Review log shows at least one completed assurance meeting
  id: CR-EA-06
  priority: medium
  steps:
  - Create AI Assurance Plan linking artifacts from CR-EA tasks
  - Schedule quarterly reviews and update evidence mapping
  - Document risk management decisions
  title: Adopt Formal AI Assurance Lifecycle
- acceptance_criteria:
  - given multilingual data
  - when ingested
  - then equivalent entities are linked via owl:sameAs
  id: RE-06
  priority: medium
  steps:
  - implement translation layer in KG ingestion
  - align entities across languages
  title: Enable Cross-Lingual Knowledge-Graph Support
- acceptance_criteria:
  - memory writes add calibrated noise
  - integration tests verify privacy budget accounting
  id: RE-07
  priority: medium
  steps:
  - add DP mechanisms to LTM writes
  - expose configuration for epsilon values
  title: Deploy Differential-Privacy LTM Architecture
- acceptance_criteria:
  - Given an active run, when the dashboard loads, then the execution graph is displayed
  - Metrics update live and clicking a node shows its detailed metrics
  id: FI-01
  priority: medium
  steps:
  - Build a web-based UI to visualize the agent execution graph in real time
  - Stream tracing events to update node status and metrics
  - Provide drill-down views for individual node performance
  title: Add Interactive Graph Monitoring Dashboard
- acceptance_criteria:
  - Tools installed as plugins are auto-discovered on startup
  - Example plugin registers successfully without code changes
  id: FI-02
  priority: medium
  steps:
  - Define entry-point interface for external tool plugins
  - Load plugins dynamically during registry startup
  - Document plugin creation with an example package
  title: Implement Plugin Architecture for Tool Registry
- acceptance_criteria:
  - Agents send and receive events through the message bus
  - Failed deliveries are retried until acknowledged
  id: FI-03
  priority: medium
  steps:
  - Add NATS or similar message bus for async task events
  - Update orchestration engine to publish and subscribe to events
  - Add tests verifying message delivery and retries
  title: Integrate Message Bus for Inter-Agent Communication
- acceptance_criteria:
  - Documentation builds successfully
  - Readers can follow the steps to create a new agent folder with working config
  id: FI-04
  priority: medium
  steps:
  - Create a "Contributing Agents" section in docs
  - Document the folder structure, config.yml, and prompt.tpl.md
  - Provide a minimal example of creating a custom agent
  title: Add Documentation on Extending Agents
- acceptance_criteria:
  - All new tests pass under `pytest -q`
  - Edge routing and recovery scenarios are validated
  id: FI-05
  priority: medium
  steps:
  - Review current integration test coverage
  - Add test cases for edge routing and failure recovery
  - Use `pytest -q` to run and verify new tests
  title: Enhance Integration Tests for Orchestration Engine
- acceptance_criteria:
  - Middleware logs errors with useful context
  - README shows how to enable/disable the middleware
  id: FI-06
  priority: low
  steps:
  - Implement middleware to capture unhandled exceptions in agent flows
  - Format logs with structured data for better tracing
  - Update the README with configuration instructions
  title: Introduce Error Logging Middleware
- acceptance_criteria:
  - '`docs/ARCHITECTURE.md` in the repo root, linked from README.'
  - Diagram files under `docs/diagrams/` in SVG or Markdown mermaid format.
  id: CR-ARCH-001
  priority: high
  steps:
  - 'Create `docs/ARCHITECTURE.md` describing core components: Orchestrator, Agents,
    Memory, Tool Registry, Tracing.'
  - "Illustrate data flows with at least one sequence diagram (e.g. \"web_researcher\
    \ \u2192 orchestrator \u2192 memory \u2192 trace\")."
  - Add 'Getting Started' section showing how to spin up services locally (vector
    DB stub, tracing backend).
  title: Draft High-Level System Design & Onboarding Guide
- acceptance_criteria:
  - 'No `# type: ignore` in `agents/` or `engine/`.'
  - CI fails on any new type errors.
  id: CR-TYPING-002
  priority: medium
  steps:
  - Audit all `agents/*.py` and `engine/orchestration_engine.py` for missing function
    and class type hints.
  - Add Pydantic models or `typing.Protocols` for message payloads and state objects.
  - Enforce via mypy in CI (add `mypy.ini` and `ci.yml` step).
  title: Add Type Annotations to Public APIs
- acceptance_criteria:
  - A new 'schema-validation' workflow in `.github/workflows/`.
  - Tests under `tests/schema/` that assert validity.
  id: CR-CI-003
  priority: medium
  steps:
  - Add a CI job that loads the graph and tool-registry OpenAPI specs and validates
    them against sample requests in `tests/fixtures/`.
  - Use `jsonschema` or `openapi-core` to fail the build on schema drift.
  - Cover at least memory service, tool registry and tracing schemas.
  title: Enforce End-to-End Schema Validation
- acceptance_criteria:
  - "Coverage report artifact shows \u226585% on `engine/`."
  - CI job fails if coverage drops below threshold.
  id: CR-COVERAGE-004
  priority: low
  steps:
  - Write unit tests for edge conditions in `engine/orchestration_engine.py` (e.g.
- acceptance_criteria:
  - docs/onboarding.md includes a troubleshooting section with pip and Docker tips
  - Quick start mentions the minimal bootstrap script
  id: DEVEXP-001
  priority: low
  steps:
  - Document common pip resolver failures and Docker setup quirks
  - Reference `scripts/bootstrap_minimal.sh` for a lightweight environment
  - Highlight environment variables for proxy and GPU configuration
  title: Improve Onboarding Guide with Troubleshooting Tips
- acceptance_criteria:
  - Tool initialization is traceable end-to-end in collected spans
  - Unit tests cover a failure case and ensure span emission
  id: DEVEXP-002
  priority: medium
  steps:
  - Instrument each tool wrapper to emit a span when the tool is constructed
  - Capture initialization parameters and any failures
  - Verify spans appear in the observability backend during tests
  title: Add Tracing Spans for Tool Initialization
- acceptance_criteria:
  - CI logs end with a concise table of failed steps and artifact URLs
  id: DEVEXP-003
  priority: low
  steps:
  - Update CI scripts to print a final summary of failing checks
  - Link directly to coverage and other artifacts in the summary
  title: Clarify CI Output Summary
- acceptance_criteria:
  - Developers can run `pytest -m "core"` to skip optional tests
  id: DEVEXP-004
  priority: low
  steps:
  - Mark expensive tests with a custom pytest marker
  - Add a script or docs to run only the core test suite
  title: Trim or Group Optional Tests
