name: Integration Benchmarks

on:
  schedule:
    - cron: '0 0 * * *'
  workflow_dispatch:

jobs:
  run-browsecomp-benchmark:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    env:
      GITHUB_TOKEN: ${{ github.token }}
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          cache: 'pip'
          cache-dependency-path: requirements.txt
      - name: Setup environment
        run: bash scripts/agent-setup.sh
      - name: Run BrowseComp benchmark harness
        run: |
          python tests/benchmarks/integration_harness.py \
            --timeout 60 \
            --retries 1 \
            --retry-delay 0.5

  run-adversarial-benchmark:
    runs-on: ubuntu-latest
    permissions:
      contents: read
    env:
      GITHUB_TOKEN: ${{ github.token }}
    steps:
      - uses: actions/checkout@v3
      - uses: actions/setup-python@v4
        with:
          python-version: '3.12'
          cache: 'pip'
          cache-dependency-path: requirements.txt
      - name: Setup environment
        run: bash scripts/agent-setup.sh
      - name: Run adversarial pipeline
        id: run-adv
        continue-on-error: true
        run: |
          python benchmarks/adversarial_pipeline.py > adv_metrics.json
          echo "exitcode=$?" >> "$GITHUB_OUTPUT"
      - name: Upload metrics
        uses: actions/upload-artifact@v4
        with:
          name: adversarial-metrics
          path: adv_metrics.json
      - name: Summarize metrics
        if: always()
        run: |
          echo "## Adversarial Metrics" >> "$GITHUB_STEP_SUMMARY"
          cat adv_metrics.json >> "$GITHUB_STEP_SUMMARY"
      - name: Fail on threshold
        if: steps.run-adv.outputs.exitcode != '0'
        run: exit 1
